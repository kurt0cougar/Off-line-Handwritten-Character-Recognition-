{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prototype of handwriten text recognition software(Keras implementation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I am going to import most of the modules That will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.29 ms\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense,Conv2D,Flatten,BatchNormalization,LSTM,Bidirectional,Lambda\n",
    "from keras.layers import Activation,MaxPooling2D,TimeDistributed,Input,Reshape,Permute\n",
    "from keras.initializers import TruncatedNormal\n",
    "from keras.optimizers import RMSprop,Adam,SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xml.etree.ElementTree as ET\n",
    "import keras.backend as K\n",
    "import glob\n",
    "import os\n",
    "import keras\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from keras.preprocessing import sequence\n",
    "import itertools\n",
    "from tensorflow.python.ops import ctc_ops as ctc\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "import random\n",
    "import editdistance\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directory structure, all the images are in the data directory, while the labels are in the labels directory. The file containing the final code is name 'final.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'1*IjxpxWcKX8EJUVFBNFeKdA.gif'                    model.py\n",
      " \u001b[0m\u001b[01;34mdata\u001b[0m/                                            project.ipynb\n",
      " dataLoader.py                                    project-v2.ipynb\n",
      " \u001b[01;34mdataset\u001b[0m/                                         \u001b[01;34m__pycache__\u001b[0m/\n",
      " dataset_example.png                              temp.py\n",
      " directory_structure.png                          \u001b[01;34mtrained_models\u001b[0m/\n",
      " final.ipynb                                      train.py\n",
      " how_images_is_stored_in_the_data_directory.png  'Untitled Document 1'\n",
      " how_labels_are_stored.png                        Untitled.ipynb\n",
      " images.jpg                                       words.tgz\n",
      " \u001b[01;34mlabels\u001b[0m/                                          xml.tgz\n",
      "time: 139 ms\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](directory_structure.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an outlook of how the images in the data directory are organized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](how_images_is_stored_in_the_data_directory.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This image shows how labels are stored in there respective xml files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](how_labels_are_stored.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This image on the other hand gives us a preview of what the images in our dataset looks like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing some constant values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 142 ms\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "random.seed(1)\n",
    "imgSize = (160,40)\n",
    "maxTextLen = 16# for the a01 dataset and 53 for the whole dataset\n",
    "keys = ' !\"#&\\'()*+,-./0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'\n",
    "nb_labels = len(keys)+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below converts each character in the label to a number according to its index in the keys variable, for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 209 ms\n"
     ]
    }
   ],
   "source": [
    "def text_to_num(txt):\n",
    "    indices = []\n",
    "    values = []\n",
    "    shape = [len(txt),53]\n",
    "    y_len = np.asarray([len(i) for i in txt])\n",
    "\n",
    "    for (batchElement, text) in enumerate(txt):\n",
    "        labelStr = [keys.index(c) for c in text]\n",
    "\n",
    "        if len(labelStr)>shape[1]:\n",
    "            shape[1] = len(labelStr)\n",
    "\n",
    "        for (i, label) in enumerate(labelStr):\n",
    "            indices.append([batchElement, i])\n",
    "            values.append(label)\n",
    "    \n",
    "    array = np.zeros(shape)\n",
    "    for j,i in enumerate(indices):\n",
    "        array[i[0],i[1]] = values[j]\n",
    "#     arr = np.zeros([shape[0],imgSize[1]])\n",
    "#     arr[0:shape[0],0:shape[1]] = array\n",
    "    \n",
    "    return array,y_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images come in various sizes so the function below reshapes them to a 160x40 size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 216 ms\n"
     ]
    }
   ],
   "source": [
    "def img_resize(img):\n",
    "    outfile = img.split('/')[-1]\n",
    "    try:\n",
    "        img = Image.open(img)\n",
    "#         img.show()\n",
    "        img.thumbnail(imgSize)\n",
    "    except IOError:\n",
    "        print (\"Failed to create thumbnail for: \",outfile)\n",
    "\n",
    "    im = np.array(img)\n",
    "    temp = np.ones([imgSize[1],imgSize[0]])*255\n",
    "    temp[0:im.shape[0],0:im.shape[1]] = im\n",
    "    image = temp/255\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 324 ms\n"
     ]
    }
   ],
   "source": [
    "def image_processing(img_list):\n",
    "    num_iter = len(img_list)\n",
    "    data = np.zeros([num_iter,imgSize[1],imgSize[0],1])\n",
    "    bad_samples = []\n",
    "    os.chdir('data/')\n",
    "    for i in range(num_iter):\n",
    "        image_name = img_list[i]+'.png'\n",
    "        # for the full dataset use:\n",
    "        #otherwise for a01 only uncomment the following line\n",
    "        try:\n",
    "            if not os.path.isfile(image_name) or not os.path.getsize(image_name):\n",
    "                bad_samples.append(image_name)\n",
    "                continue\n",
    "            data[i,:,:,0] = img_resize(image_name)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    os.chdir('..')\n",
    "#          print(os.getcwd())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 85.3 ms\n"
     ]
    }
   ],
   "source": [
    "def ctc_decode_greedy(args):\n",
    "    y_pred, input_length = args\n",
    "    print(input_length)\n",
    "    print(input_length.shape)\n",
    "    return K.cast(K.ctc_decode(y_pred,tf.squeeze(input_length),greedy=True)[0][0],dtype='float32')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 80.1 ms\n"
     ]
    }
   ],
   "source": [
    "def ctc_decode_beam_width(args):\n",
    "    y_pred,input_length = args\n",
    "    out = K.ctc_decode(y_pred,tf.squeeze(input_length),greedy=False,beam_width = 100,top_paths=1)\n",
    "    return K.cast(out[0][0],dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function as it name implies get the data, and the labels, preprocess them and then return values that our model can work with, meaning it gets the image data and convert them to array of number each of 160x40 in size, get the labels from there respective xml files and assign each label with it respective image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 81.6 ms\n"
     ]
    }
   ],
   "source": [
    "def get_data(dataset_length = 40000):\n",
    "    list_of_imgs = []\n",
    "    path_name = 'data'\n",
    "    if path_name not in os.listdir():\n",
    "        os.chdir(str(Path.home())+'/'+'internshipme/')\n",
    "    \n",
    "    # for getting a list of all images\n",
    "    list_of_imgs = os.walk(path_name)\n",
    "#    \n",
    "\n",
    "    imgs_to_labels = {}\n",
    "    # change to ../labels for whole dataset, current dir structure == '/home/keke/internshipme/dataset/a01'\n",
    "    # and ../../labels for a01\n",
    "    path = 'labels/'\n",
    "    list_of_dirs = os.listdir('labels')\n",
    "   \n",
    "    for folder in list_of_dirs:\n",
    "        path_name = path+folder\n",
    "        tree = ET.parse(path_name) \n",
    "        root = tree.getroot() \n",
    "        for word in root.iter('word'): \n",
    "            imgs_to_labels[word.attrib['id']]=word.attrib['text']\n",
    "    temp_keys = list(imgs_to_labels.keys())\n",
    "    temp_keys = random.sample(temp_keys,dataset_length)\n",
    "\n",
    "    temp_values = [[value for value in imgs_to_labels[i]] for i in temp_keys]\n",
    "#     temp_values = list(imgs_to_labels.values())\n",
    "    print('This the number of variables: ',len(temp_keys))\n",
    "    print('This is the number of values: ',len(temp_values))\n",
    "    X = image_processing(temp_keys)\n",
    "    Y,y_len = text_to_num(temp_values)\n",
    "\n",
    "    X_train,X_test,Y_train_cat,Y_test,y_train_len,y_test_len = train_test_split(X,Y,y_len,train_size=0.7,random_state=1,shuffle=True)\n",
    "    X_val,X_test,Y_val_cat,Y_test_cat,y_val_len,y_test_len = train_test_split(X_test,Y_test,y_test_len,test_size=0.3,random_state=1,shuffle=True)\n",
    "    \n",
    "\n",
    "    nb_train = len(X_train)\n",
    "    nb_test = len(X_test)\n",
    "    nb_val = len(X_val)\n",
    "\n",
    "    x_train_len = np.asarray([imgSize[1] for i in range(nb_train)])\n",
    "    x_test_len = np.asarray([imgSize[1] for i in range(nb_test)])\n",
    "    x_val_len = np.asarray([imgSize[1] for i in range(nb_val)])\n",
    "\n",
    "    print(\".............Image data processed successfully................ :)\")\n",
    "\n",
    "    print(\".............Label data successfully converted............... :) \")\n",
    "    return imgs_to_labels,X_train,X_val,X_test,Y_train_cat,Y_val_cat,Y_test_cat,x_train_len,x_val_len,x_test_len,y_train_len,y_val_len,y_test_len\n",
    "#     return imgs_to_labels,list_of_dirs,list_of_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 97.2 ms\n"
     ]
    }
   ],
   "source": [
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    " \n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 99.9 ms\n"
     ]
    }
   ],
   "source": [
    "def num_to_text(y):\n",
    "    list_of_text = []\n",
    "    for i in y:\n",
    "        l = list(i)\n",
    "        string = ''\n",
    "        for j in l:\n",
    "            j = int(j)\n",
    "            if j!=-1:\n",
    "                string+=keys[j]\n",
    "        list_of_text.append(string)\n",
    "    return list_of_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 123 ms\n"
     ]
    }
   ],
   "source": [
    "def myModel(maxTextLen,l2):\n",
    "    input_data = Input(shape=(40,160,1))\n",
    "    # input_length = Input(shape)\n",
    "    X = Conv2D(32,kernel_size=(5,5),strides=(1,1),padding='SAME',kernel_regularizer=keras.regularizers.l2(l=l2))(input_data)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='valid')(X)\n",
    "\n",
    "    X = Conv2D(64,kernel_size=(5,5),strides=(1,1),padding='SAME')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    \n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='valid')(X)\n",
    "\n",
    "    X=Conv2D(128,kernel_size=(3,3),strides=(1,1),padding='SAME',kernel_regularizer=keras.regularizers.l2(l=l2))(X)\n",
    "    X=BatchNormalization()(X)\n",
    "    X=Activation('relu')(X)\n",
    "    X=MaxPooling2D(pool_size=(2,1),strides=(2,1),padding='valid')(X)\n",
    "\n",
    "    X=Conv2D(128,kernel_size=(3,3),strides=(1,1),padding='SAME',kernel_regularizer=keras.regularizers.l2(l=l2))(X)\n",
    "    X=BatchNormalization()(X)\n",
    "    X=Activation('relu')(X)\n",
    "    X=MaxPooling2D(pool_size=(2,1),strides=(2,1),padding='valid')(X)\n",
    "\n",
    "    X=Conv2D(256,kernel_size=(3,3),strides=(1,1),padding='SAME',kernel_regularizer=keras.regularizers.l2(l=l2))(X)\n",
    "    X=BatchNormalization()(X)\n",
    "    X=Activation('relu')(X)\n",
    "    X=MaxPooling2D(pool_size=(2,1),strides=(2,1),padding='valid')(X)\n",
    "    \n",
    "    X = Reshape([40,256])(X)\n",
    "    X=Bidirectional(LSTM(256, return_sequences=True,kernel_regularizer=keras.regularizers.l2(l=l2)),merge_mode='concat')(X)\n",
    "    X=Bidirectional(LSTM(256,return_sequences=True,kernel_regularizer=keras.regularizers.l2(l=l2)),merge_mode='concat')(X)\n",
    "#     X = Reshape([32,512,1])(X)\n",
    "    outputs = Dense(80,name=\"dense\",activation='softmax',kernel_regularizer=keras.regularizers.l2(l=l2))(X)\n",
    "#     X = Conv2D(80,kernel_size=(1,512),strides=(1,1),kernel_initializer=TruncatedNormal(stddev=0.1))(X)\n",
    "#     outrnn = Reshape([32,80])(outrnn)\n",
    "\n",
    "#     outrnn = Lambda(lambda input:tf.transpose(input,[1,0,2]))(outrnn)\n",
    "    model = Model(inputs=input_data,outputs=outputs)\n",
    "    model.summary()\n",
    "    \n",
    "    labels = Input(name='the_labels', shape=[maxTextLen], dtype='float32')\n",
    "    input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "    label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    " \n",
    "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([outputs, labels, input_length, label_length])\n",
    "    out_decoded_greedy = Lambda(ctc_decode_greedy,output_shape=(None,None),name='CTCdecodegreedy')([outputs,input_length])\n",
    "    out_decoded_beam = Lambda(ctc_decode_beam_width,output_shape=(None,None),name='CTCdecodebeam')([outputs,input_length])\n",
    "    model_train = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n",
    "    model_predict_greedy = Model(inputs=[input_data,input_length],outputs=out_decoded_greedy)\n",
    "    model_predict_beam = Model(inputs=[input_data,input_length],outputs = out_decoded_beam)\n",
    "    return model,model_train,model_predict_greedy,model_predict_beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This the number of variables:  40000\n",
      "This is the number of values:  40000\n",
      ".............Image data processed successfully................ :)\n",
      ".............Label data successfully converted............... :) \n",
      "time: 11min 37s\n"
     ]
    }
   ],
   "source": [
    " imgs_to_labels,X_train,X_val,X_test,Y_train_cat,Y_val_cat,Y_test_cat,x_train_len,x_val_len,x_test_len,y_train_len,y_val_len,y_test_len = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8400, 40, 160, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 81 ms\n"
     ]
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3600, 40, 160, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.74 ms\n"
     ]
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 40, 160, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.38 ms\n"
     ]
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 40, 160, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 40, 160, 32)       832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 40, 160, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 40, 160, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 20, 80, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 20, 80, 64)        51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 20, 80, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 20, 80, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 10, 40, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 10, 40, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 10, 40, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 10, 40, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 5, 40, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 5, 40, 128)        147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 5, 40, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 5, 40, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 2, 40, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 2, 40, 256)        295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 2, 40, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 2, 40, 256)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 1, 40, 256)        0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 40, 256)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 40, 512)           1050624   \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 40, 512)           1574912   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 40, 80)            41040     \n",
      "=================================================================\n",
      "Total params: 3,237,712\n",
      "Trainable params: 3,236,496\n",
      "Non-trainable params: 1,216\n",
      "_________________________________________________________________\n",
      "Tensor(\"input_length_1:0\", shape=(None, 1), dtype=int64)\n",
      "(None, 1)\n",
      "time: 1.57 s\n"
     ]
    }
   ],
   "source": [
    "l2 = 0.01\n",
    "# maxTextLen = Y_train_cat.shape[1]\n",
    "model,model_train,model_predict_greedy,model_predict_beam = myModel(53,l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.59 ms\n"
     ]
    }
   ],
   "source": [
    "def train(model_train,file_path,X_train,Y_train_cat,x_train_len,y_train_len,X_val,Y_val_cat,x_val_len,y_val_len,batch_size=32,epochs=30):\n",
    "    model_train.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer = 'adam')\n",
    " \n",
    "    checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "    callbacks_list = [checkpoint]\n",
    "    model_train.fit(x=[X_train,Y_train_cat,x_train_len,y_train_len],y=np.zeros(X_train.shape[0]),batch_size=32,epochs = 30,validation_data = ([X_val,Y_val_cat,x_val_len,y_val_len],[np.zeros(X_val.shape[0])]),verbose=1,callbacks=callbacks_list)\n",
    "    print(\"------Training completed--------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.87 ms\n"
     ]
    }
   ],
   "source": [
    "def error_rate(X_test,Y_test,x_test_len,model_path='trained_models/model_40000.hdf5'):\n",
    "    char_error = 0\n",
    "    batch_size = 32\n",
    "    num_char = 0\n",
    "    num_word = 0\n",
    "    num_correct_word = 0\n",
    "    \n",
    "    num_of_batch = len(X_test//batch_size)\n",
    "    iterator = 0\n",
    "    disp = 0\n",
    "    while iterator<=num_of_batch:\n",
    "        \n",
    "        model_predict_greedy.load_weights(model_path)\n",
    "        prediction = model_predict_greedy.predict([X_test[iterator:iterator+batch_size],x_test_len[iterator:iterator+batch_size]])\n",
    "        list_of_prediction = num_to_text(prediction)\n",
    "        ground_truths = num_to_text(Y_test[iterator:iterator+batch_size])\n",
    "        iterator+=batch_size\n",
    "\n",
    "        if disp == 0:\n",
    "            disp = 1\n",
    "            print(\"These are the ground truths and predicted values for the first ten examples in the test set\")\n",
    "            print(\"\\nGround truth  ->   Predicted value\")\n",
    "            print(\"\\n----------------------------------\\n\")\n",
    "            for i in range(10):\n",
    "                print(ground_truths[i].strip(),'----->',list_of_prediction[i])\n",
    "        for i in range(len(list_of_prediction)):\n",
    "            ground_truth = ground_truths[i].strip()\n",
    "            num_correct_word+= 1 if ground_truth == list_of_prediction[i] else 0\n",
    "            num_word+=1\n",
    "            distance = editdistance.eval(list_of_prediction[i],ground_truth.strip())\n",
    "            char_error += distance\n",
    "            num_char += len(ground_truth)\n",
    "\n",
    "    \n",
    "    char_error_rate = char_error/num_char\n",
    "    word_accuracy = num_correct_word/num_word\n",
    "    print('\\nCharacter Error Rate: %.2f%%'%(char_error_rate*100.0),'|  Word Accuracy: %.2f%%'%(word_accuracy*100.0))    \n",
    "    return char_error_rate,word_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the ground truths and predicted values for the first ten examples in the test set\n",
      "\n",
      "Ground truth  ->   Predicted value\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "on -----> on\n",
      "unguarded -----> onsvardes\n",
      "the -----> the\n",
      "help -----> hely\n",
      "the -----> the\n",
      "couples -----> comples\n",
      "Caxtons -----> Castons\n",
      "firmly -----> firely\n",
      "with -----> with\n",
      "the -----> the\n",
      "\n",
      "Character Error Rate: 20.68% |  Word Accuracy: 55.67%\n",
      "time: 43.8 s\n"
     ]
    }
   ],
   "source": [
    "char_error_rate,word_accuracy = error_rate(X_test,Y_test_cat,x_test_len,model_path='trained_models/model_40000.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
